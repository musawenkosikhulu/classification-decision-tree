# -*- coding: utf-8 -*-
"""AIMS_DS_2022_DT_1.ipynb

Automatically generated by Colaboratory.

Original file is located at
    https://colab.research.google.com/drive/10pQ6lMTEF7i4W4zXcgGp6k-TCAga0Mr5

Monday 3rd Jan 2022

Decision tree practical

On the left, click on the folder icon and upload the pima_data.csv file.
"""

import pandas as pd
from sklearn.tree import DecisionTreeClassifier
from sklearn.model_selection import train_test_split
from sklearn.metrics import accuracy_score

"""## Read in the data"""

col_names = ['pregnant', 'glucose', 'bp', 'skin', 'insulin', 'bmi', 'pedigree', 'age', 'label']
# load dataset
pima = pd.read_csv("pima_data.csv", header=None, names=col_names)

pima.head()

pima.describe()

len(pima)

"""## Create X and y variables (features and target)"""

feature_cols = ['pregnant', 'insulin', 'bmi', 'age','glucose','bp','pedigree', 'skin']
X = pima[feature_cols] # Features
y = pima.label # Target variable

X

y

"""## Split data into training and testing"""

X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.3, random_state=4278) # 70% training and 30% test

"""## Whenever you do some data manipulation, you should always check the resulting data"""

X_train.shape

y_train.shape

X_test.shape

y_test.shape

"""## Use scikit-learn decision tree object

API: https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html
"""

# Create decision tree classifier using entropy
clf = DecisionTreeClassifier(criterion='entropy', max_depth =6)

# Train Decision Tree Classifer on the training data
clf = clf.fit(X_train,y_train)

#Predict the targets for test dataset
y_pred = clf.predict(X_test)

"""## Evaluate on testing data"""

# Compare the model predictions to the true values on the test data
print("Accuracy:",accuracy_score(y_test, y_pred)*100)

"""## Visualise the decision tree"""

!pip install graphviz

import graphviz
from sklearn import tree
dot_data = tree.export_graphviz(clf, out_file=None, 
                                feature_names=feature_cols,  
                                class_names=['0', '1'],
                                filled=True)

# Draw graph
graph = graphviz.Source(dot_data, format="png") 
graph

"""## Task

Read through the decision tree API https://scikit-learn.org/stable/modules/generated/sklearn.tree.DecisionTreeClassifier.html and re-run this code using a different value for the maximum depth (don't pick a value larger than 10). You will need to specify this new arguement in the function which creates the decision tree. Which maximum depth gave you the best test accuracy?

The max depth that gives good test accuracy was 5.

## Recap

*   Decision trees are easy to interpret and visualize.
*   There is no need to normalize data.
*   The model does not learn any parameters (we will learn about parameterised models later on). We simply induce a tree and that is it.
*   It is sensitive to noisy data

visualize.
"""

